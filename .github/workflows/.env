# (Create this manually in root and use with python-dotenv if needed)
FASTAPI_PORT=8000
DATA_DIR=./data/processed


# âœ… Spark job example: src/transformation/spark_job.py
from pyspark.sql import SparkSession

def main():
    spark = SparkSession.builder.appName("DataTransform").getOrCreate()
    df = spark.read.option("header", True).csv("data/raw/eia.csv")
    df_cleaned = df.dropna()
    df_cleaned.write.parquet("data/processed/example.parquet", mode="overwrite")

if __name__ == "__main__":
    main()
